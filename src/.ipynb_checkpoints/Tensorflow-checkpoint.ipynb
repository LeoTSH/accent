{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L-4QJfKPmBeH",
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Import-packages\" data-toc-modified-id=\"Import-packages-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Import packages</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24403,
     "status": "ok",
     "timestamp": 1568675762353,
     "user": {
      "displayName": "Leo Tay",
      "photoUrl": "",
      "userId": "17143338865945125396"
     },
     "user_tz": -480
    },
    "id": "n0skNmermLnH",
    "outputId": "46f51b4f-8446-46f8-fbc1-a917781a959a"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1994,
     "status": "ok",
     "timestamp": 1568675765343,
     "user": {
      "displayName": "Leo Tay",
      "photoUrl": "",
      "userId": "17143338865945125396"
     },
     "user_tz": -480
    },
    "id": "VAK6-JRSmR9O",
    "outputId": "300f6273-73dc-4277-e005-dd8be6908b0f"
   },
   "outputs": [],
   "source": [
    "# %cd /content/drive/My Drive/Colab Notebooks/accent/src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-05T05:03:26.979689Z",
     "start_time": "2019-09-05T05:03:23.393541Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6380,
     "status": "ok",
     "timestamp": 1568675773582,
     "user": {
      "displayName": "Leo Tay",
      "photoUrl": "",
      "userId": "17143338865945125396"
     },
     "user_tz": -480
    },
    "id": "IdpwZH_SmBeI",
    "outputId": "a23337f0-e5a2-439f-87d6-ab806eaaea33"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf, re, zipfile, os, io, time, string, numpy as np, matplotlib.ticker as ticker, \\\n",
    "            matplotlib.pyplot as plt\n",
    "\n",
    "# from utils import process_raw, generate_input, get_max_len, process_data, convert\n",
    "\n",
    "from token_list import strip_tokens\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = ['Khoan no cua KH se den han vao 01/08/2019. So tien  2.999.898 VND, TK 12345678912. Thong tin chi tiet, lien he 1900636633. Cam on',\n",
    "# 'Khoan no cua KH se den han trong 2 ngay toi. So tien  2.999.898 VND, TK 12345678912. Bo qua neu da TT. Thong tin chi tiet, lien he 1900636633. Cam on',\n",
    "# 'Khoan no cua KH da qua han 1 ngay. TK 12345678912, so tien2.999.898 VND. Bo qua neu da TT. Thong tin chi tiet, lien he 18006288',\n",
    "# 'Khoan no cua KH da qua han 6 ngay va bi tinh phat 250,000. TK 12345678912, so tien 2.999.898VND. Vui long TT. Thong tin chi tiet, lien he 18006288',\n",
    "# 'KH da qua han 5 ky no. TK 12345678912, so tien 12.999.898VND. Vui long TT ngay lap tuc. Thong tin chi tiet, lien he 18006288',\n",
    "# 'Khoan no cua KH da bi tinh phat do lien tuc vi pham. TK12345678912, so tien 12.999.898VND. Vui long TT. Thong tin chi tiet, lien he 18006288',\n",
    "# 'Khoan no cua KH da qua han 91 ngay. Vui long TT toan bo29.999.898VND vao TK 12345678912 hom nay. Thong tin chi tiet, lien he 18006288',\n",
    "# 'Chung toi vua nhan thanh toan khoan vay cua KH tu TK12345678912. TUY NHIEN, KH van con thieu 29.999.898VND. Vui long TT toan ngay lap tuc. Cam on']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "np.random.seed(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2218,
     "status": "ok",
     "timestamp": 1568675773582,
     "user": {
      "displayName": "Leo Tay",
      "photoUrl": "",
      "userId": "17143338865945125396"
     },
     "user_tz": -480
    },
    "id": "hzE5KWyzmiI2",
    "outputId": "465e3f00-d7be-4d14-88b7-1f18d7d5af5d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0-rc1'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t3Yl7IcWmBeL"
   },
   "outputs": [],
   "source": [
    "def process_raw(raw_data):\n",
    "    raw_data = [seq.lower().strip() for seq in raw_data]\n",
    "\n",
    "    # Creating a space between a word and the punctuation following it\n",
    "    # Eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "    raw_data = [re.sub(r\"([?.!,¿])\", r\" \\1 \", seq) for seq in raw_data]\n",
    "    raw_data = [re.sub(r'[\" \"]+', \" \", seq) for seq in raw_data]\n",
    "\n",
    "    # Replacing everything with space except (characters, \".\", \"?\", \"!\", \",\")\n",
    "    filtered_punctuations = string.punctuation\n",
    "    exclude = [',', '!', '.', '?']\n",
    "\n",
    "    for c in filtered_punctuations:\n",
    "        if c in exclude:\n",
    "            filtered_punctuations = filtered_punctuations.replace(c, '')\n",
    "\n",
    "    table = str.maketrans('', '', filtered_punctuations)\n",
    "    raw_data = [seq.translate(table) for seq in raw_data]\n",
    "    \n",
    "    # Append start and end tokens to sequences\n",
    "    processed_raw = []\n",
    "    for seq in raw_data:\n",
    "        words = seq.split()\n",
    "        words = [word.strip() for word in words]\n",
    "        processed_raw.append(' '.join(words))\n",
    "\n",
    "    # processed_raw = ['<s> ' + seq + ' <e>' for seq in processed_raw]\n",
    "    processed_raw = ['<s> ' + seq + ' <e>' for seq in processed_raw]\n",
    "\n",
    "    return processed_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tTLjwvPomBeN"
   },
   "outputs": [],
   "source": [
    "def generate_input(processed_raw):\n",
    "    output = ''\n",
    "    for char in processed_raw:\n",
    "        if char in strip_tokens:\n",
    "            output += strip_tokens[char]\n",
    "        else:\n",
    "            output += char          \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IJz8C1jjmBeP"
   },
   "outputs": [],
   "source": [
    "def get_max_len(input_data, get_index=False): \n",
    "    longest = [len(data.split()) for data in input_data]\n",
    "    if get_index:\n",
    "        print(longest.index(max(longest)))\n",
    "    return max(longest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e9ar4oQxmBeQ"
   },
   "outputs": [],
   "source": [
    "def tokenize_pad_data(data, pad_len=None):\n",
    "    tk = Tokenizer(char_level=False, filters='')\n",
    "    tk.fit_on_texts(data)\n",
    "    data = tk.texts_to_sequences(data)\n",
    "    data = pad_sequences(data, padding='post', maxlen=pad_len)\n",
    "    return data, tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SmsFiMrtmBeS"
   },
   "outputs": [],
   "source": [
    "def process_data(processed_input, processed_target, pad_len=None):    \n",
    "    tokenized_input, input_tokenizer = tokenize_pad_data(data=processed_input, pad_len=pad_len)\n",
    "    tokenized_target, target_tokenizer = tokenize_pad_data(data=processed_target, pad_len=pad_len)\n",
    "    return tokenized_input, input_tokenizer, tokenized_target, target_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Fw9xOpCmBeT"
   },
   "outputs": [],
   "source": [
    "def convert(tokenizer, tokenized_data, send_back=False):\n",
    "    original = []\n",
    "    \n",
    "    print('Tokenized Data: {}'.format(tokenized_data))\n",
    "    print('\\n')\n",
    "    \n",
    "    for token in tokenized_data:\n",
    "        if token != 0:\n",
    "            if token in tokenizer.index_word:\n",
    "                original.append(tokenizer.index_word[token])\n",
    "            else:\n",
    "                original.append('<unk>')\n",
    "                    \n",
    "    print('Original Data: {}'.format(original))\n",
    "    \n",
    "    if send_back:\n",
    "        return original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5rzxmuS-mBeV"
   },
   "outputs": [],
   "source": [
    "# Define data arguements\n",
    "data_file = '../data/raw/raw_train.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mpeUU7WdmBeX"
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "counter = 0\n",
    "max_seq_len = 35\n",
    "no_seq = 100000\n",
    "raw_data = []\n",
    "\n",
    "# Load raw data and read first 100000 sequences with 40 or less words\n",
    "with open(data_file, 'r', encoding='utf-8') as f:    \n",
    "    while counter != no_seq:\n",
    "        line = f.readline()\n",
    "        if len(line.split()) <= max_seq_len:\n",
    "            raw_data.append(line)\n",
    "            counter += 1\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6539,
     "status": "ok",
     "timestamp": 1568675789604,
     "user": {
      "displayName": "Leo Tay",
      "photoUrl": "",
      "userId": "17143338865945125396"
     },
     "user_tz": -480
    },
    "id": "8qXuFMzlmBeZ",
    "outputId": "47d0a4b7-254d-4467-9bea-f4ba27878512"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max input sequence length: 51\n",
      "Max target sequence length: 51\n"
     ]
    }
   ],
   "source": [
    "# Process dataset\n",
    "# From the 1000000 sequences, randomly pick 20000\n",
    "random_pick = 20000\n",
    "random_idx = np.random.choice(no_seq, random_pick, replace=False)\n",
    "raw_data = [raw_data[i] for i in random_idx]\n",
    "\n",
    "# Shuffle raw data prior to processing\n",
    "np.random.shuffle(raw_data)\n",
    "\n",
    "# Process raw and input data\n",
    "filtered_raw = process_raw(raw_data)\n",
    "processed_inp = [generate_input(seq) for seq in filtered_raw]\n",
    "\n",
    "# Get max sequence length after processing\n",
    "max_process_seq = get_max_len(processed_inp, get_index=False)\n",
    "print('Max input sequence length: {}'.format(get_max_len(processed_inp)))\n",
    "print('Max target sequence length: {}'.format(get_max_len(filtered_raw)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6428,
     "status": "ok",
     "timestamp": 1568675789605,
     "user": {
      "displayName": "Leo Tay",
      "photoUrl": "",
      "userId": "17143338865945125396"
     },
     "user_tz": -480
    },
    "id": "o_H9BS41mBed",
    "outputId": "baa286a3-4224-405b-9a43-2a61c95777dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Sample:\n",
      "<s> viet nam thi van hop tuyen cua duong quang ham co ghi lai ca dao ve 36 sau pho o ha noi nhu sau <e>\n",
      "\n",
      "\n",
      "Target Sample:\n",
      "<s> việt nam thi văn hợp tuyển của dương quảng hàm có ghi lại ca dao về 36 sáu phố ở hà nội như sau <e>\n"
     ]
    }
   ],
   "source": [
    "print('Input Sample:')\n",
    "print(processed_inp[-1])\n",
    "print('\\n')\n",
    "print('Target Sample:')\n",
    "print(filtered_raw[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-N7GaOalmBee"
   },
   "outputs": [],
   "source": [
    "# Tokenize/pad input and target data, generates corresponding tokenizers\n",
    "tokenized_input, input_tokenizer, tokenized_target, target_tokenizer = process_data(processed_input=processed_inp, \n",
    "                                                            processed_target=filtered_raw, pad_len=max_process_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11997,
     "status": "ok",
     "timestamp": 1568675796826,
     "user": {
      "displayName": "Leo Tay",
      "photoUrl": "",
      "userId": "17143338865945125396"
     },
     "user_tz": -480
    },
    "id": "_xin5HNPmBer",
    "outputId": "9ca43151-946b-4ce9-8e32-9e4c2851fc92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sequences: 16000\n",
      "Number of val sequences: 2000\n",
      "Number of test sequences: 2000\n"
     ]
    }
   ],
   "source": [
    "train_data_len = round((.8 * random_pick))\n",
    "val_test_data_len = round((.1 * random_pick))\n",
    "\n",
    "train_inp_data, train_tar_data = tokenized_input[:train_data_len], tokenized_target[:train_data_len]\n",
    "val_inp_data, val_tar_data = tokenized_input[train_data_len:(train_data_len+val_test_data_len)], \\\n",
    "                                    tokenized_target[train_data_len:(train_data_len+val_test_data_len)]\n",
    "test_inp_data, test_tar_data = tokenized_input[-val_test_data_len:], tokenized_target[-val_test_data_len:]\n",
    "\n",
    "print('Number of training sequences: {}'.format(len(train_inp_data)))\n",
    "print('Number of val sequences: {}'.format(len(val_inp_data)))\n",
    "print('Number of test sequences: {}'.format(len(test_inp_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11114,
     "status": "ok",
     "timestamp": 1568675796827,
     "user": {
      "displayName": "Leo Tay",
      "photoUrl": "",
      "userId": "17143338865945125396"
     },
     "user_tz": -480
    },
    "id": "FhIKiOx5mBet",
    "outputId": "7ac2bd74-d947-4301-8d5a-434798616955"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Data: [  2 213 207   4 420 200  67 146 122  18  71  47   4 341 105  79 524  99\n",
      " 120 505   3   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "\n",
      "\n",
      "Original Data: ['<s>', 'tuy', 'nhien', ',', 'ro', 'rang', 'nhieu', 'sinh', 'vien', 'da', 'bi', 'ban', ',', 'sao', 'anh', 'lai', 'giet', 'chung', 'toi', '?', '<e>']\n"
     ]
    }
   ],
   "source": [
    "convert(input_tokenizer, train_inp_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dquKNOnxmBez",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_buffer_sz = len(train_inp_data)\n",
    "val_buffer_sz = len(val_inp_data)\n",
    "batch_sz = 64\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_inp_data, train_tar_data)).shuffle(train_buffer_sz)\n",
    "train_dataset = train_dataset.batch(batch_sz, drop_remainder=True)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_inp_data, val_tar_data)).shuffle(val_buffer_sz)\n",
    "val_dataset = val_dataset.batch(batch_sz, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11784,
     "status": "ok",
     "timestamp": 1568675798570,
     "user": {
      "displayName": "Leo Tay",
      "photoUrl": "",
      "userId": "17143338865945125396"
     },
     "user_tz": -480
    },
    "id": "VqOnBUExmBe3",
    "outputId": "77152e8e-4beb-4790-fe3e-c2537730ecc7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 51])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(train_dataset))\n",
    "example_input_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11179,
     "status": "ok",
     "timestamp": 1568675798571,
     "user": {
      "displayName": "Leo Tay",
      "photoUrl": "",
      "userId": "17143338865945125396"
     },
     "user_tz": -480
    },
    "id": "Vehr9V-GmBe4",
    "outputId": "45067b83-4370-47a8-9811-a8d3a5cdc0ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 51])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_target_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 51])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_val_inp_batch, example_val_tar_batch = next(iter(val_dataset))\n",
    "example_val_inp_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 51])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_val_tar_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9958,
     "status": "ok",
     "timestamp": 1568675798571,
     "user": {
      "displayName": "Leo Tay",
      "photoUrl": "",
      "userId": "17143338865945125396"
     },
     "user_tz": -480
    },
    "id": "JMqR7Y6umBe6",
    "outputId": "ae1511e3-131b-41fc-b113-c34cc305429f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n",
      "12703\n",
      "15646\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 256\n",
    "units = 1024\n",
    "dropout = 0.2\n",
    "inp_vocab_sz = len(input_tokenizer.index_word)+1\n",
    "tar_vocab_sz = len(target_tokenizer.index_word)+1\n",
    "\n",
    "print(steps_per_epoch)\n",
    "print(inp_vocab_sz)\n",
    "print(tar_vocab_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cj-IlNQsmBe7"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super().__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units, return_sequences=True, return_state=True, \n",
    "                                       recurrent_initializer='glorot_uniform', dropout=dropout)\n",
    "            \n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14274,
     "status": "ok",
     "timestamp": 1568675803993,
     "user": {
      "displayName": "Leo Tay",
      "photoUrl": "",
      "userId": "17143338865945125396"
     },
     "user_tz": -480
    },
    "id": "-cZZxz3WmBe9",
    "outputId": "7c435948-b13e-4d1a-dafe-5276f9563063"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (64, 51, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(inp_vocab_sz, embedding_dim, units, batch_sz)\n",
    "\n",
    "# sample input\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i2LssOB5rGBV"
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        # hidden shape == (batch_size, hidden size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # we are doing this to perform addition to calculate the score\n",
    "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = self.V(tf.nn.tanh(self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14520,
     "status": "ok",
     "timestamp": 1568675804592,
     "user": {
      "displayName": "Leo Tay",
      "photoUrl": "",
      "userId": "17143338865945125396"
     },
     "user_tz": -480
    },
    "id": "iG--lBXPrsn7",
    "outputId": "ba6c005e-632f-4f4c-be2a-b87439de6322"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (64, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (64, 51, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IWUJincXmBe-"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units, return_sequences=True, return_state=True, \n",
    "                                       recurrent_initializer='glorot_uniform', dropout=dropout)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        # used for attention\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "        # passing the concatenated vector to the GRU\n",
    "        output, state = self.gru(x)\n",
    "\n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "        # output shape == (batch_size, vocab)\n",
    "        x = self.fc(output)\n",
    "\n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12823,
     "status": "ok",
     "timestamp": 1568675804594,
     "user": {
      "displayName": "Leo Tay",
      "photoUrl": "",
      "userId": "17143338865945125396"
     },
     "user_tz": -480
    },
    "id": "QJFP7gbQmBfA",
    "outputId": "ca20e316-0d41-4006-a10b-1dfb8638c1f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (64, 15646)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(tar_vocab_sz, embedding_dim, units, batch_sz)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((batch_sz, 1)), sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xmjl4_cVmBfB"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(lr=0.005)\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    \n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-E_bnkXQmBfD"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "  \n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer, encoder=encoder, decoder=decoder)\n",
    "manager = tf.train.CheckpointManager(checkpoint=checkpoint, directory=checkpoint_dir, max_to_keep=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "35xeW0fumBfF"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0.0\n",
    "    acc = 0.0\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "        dec_hidden = enc_hidden\n",
    "\n",
    "        dec_input = tf.expand_dims([target_tokenizer.word_index['<s>']] * batch_sz, 1)\n",
    "\n",
    "        # Teacher forcing - feeding the target as the next input\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            # passing enc_output to the decoder\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "#             loss += loss_function(targ[:, t], predictions)\n",
    "            train_loss = loss_object(targ[:, t], predictions)\n",
    "            loss += train_loss\n",
    "    \n",
    "            accuracy.update_state(targ[:, t], predictions)\n",
    "            acc += accuracy.result()\n",
    "            \n",
    "            # using teacher forcing\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "    batch_acc = acc / int (targ.shape[1])\n",
    "    \n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    \n",
    "    return batch_loss, batch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1741323,
     "status": "error",
     "timestamp": 1568677832895,
     "user": {
      "displayName": "Leo Tay",
      "photoUrl": "",
      "userId": "17143338865945125396"
     },
     "user_tz": -480
    },
    "id": "qSCqgFtRmBfG",
    "outputId": "96f10c85-070b-4ea6-f3b1-9e476422bfc4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 1.5760\n",
      "Epoch 1 Batch 100 Loss 1.4899\n",
      "Epoch 1 Batch 200 Loss 1.1981\n",
      "New best loss: inf --> 1.3440801615715028\n",
      "New loss: 1.3440801615715028\n",
      "Saving model\n",
      "Save completed\n",
      "Epoch 1 Training Loss 1.3441, Training Acc: 0.6693, Val Loss: 2.3309, Val Acc: val_epoch_accs\n",
      "Time taken for 1 epoch 215.3757290840149 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "train_steps_per_epoch = len(train_inp_data)//batch_sz\n",
    "val_steps_per_epoch = len(val_inp_data)//batch_sz\n",
    "best_loss = np.inf\n",
    "train_epoch_losses = []\n",
    "train_epoch_accs = []\n",
    "val_epoch_losses = []\n",
    "val_epoch_accs = []\n",
    "early_stop = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    train_total_loss = 0.0\n",
    "    train_total_acc = 0.0\n",
    "    val_total_loss = 0.0\n",
    "    val_total_acc = 0.0\n",
    "    \n",
    "    # Training\n",
    "    for (batch, (inp, targ)) in enumerate(train_dataset.take(train_steps_per_epoch)):\n",
    "        batch_loss, batch_acc = train_step(inp, targ, enc_hidden)\n",
    "#         total_loss += batch_loss\n",
    "        train_total_loss += np.average(batch_loss)\n",
    "        train_total_acc += batch_acc\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "#             print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, batch_loss.numpy()))\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, np.average(batch_loss)))\n",
    "    \n",
    "    # Validation\n",
    "    for (batch, (inp, targ)) in enumerate(val_dataset.take(val_steps_per_epoch)):\n",
    "        batch_loss, batch_acc = train_step(inp, targ, enc_hidden)\n",
    "#         total_loss += batch_loss\n",
    "        val_total_loss += np.average(batch_loss)\n",
    "        val_total_acc += batch_acc\n",
    "    \n",
    "    # Training\n",
    "    train_epoch_loss = train_total_loss/train_steps_per_epoch    \n",
    "    train_epoch_losses.append(train_epoch_loss)\n",
    "\n",
    "    train_epoch_acc = train_total_acc/train_steps_per_epoch\n",
    "    train_epoch_accs.append(train_epoch_acc)    \n",
    "    \n",
    "    # Validation\n",
    "    val_epoch_loss = val_total_loss/val_steps_per_epoch    \n",
    "    val_epoch_losses.append(val_epoch_loss)\n",
    "\n",
    "    val_epoch_acc = val_total_acc/val_steps_per_epoch\n",
    "    val_epoch_accs.append(val_epoch_acc)\n",
    "    \n",
    "    if train_epoch_loss <= best_loss:\n",
    "        print('New best loss: {} --> {}'.format(best_loss, train_epoch_loss))\n",
    "        best_loss = train_epoch_loss\n",
    "        print('New loss: {}'.format(best_loss))\n",
    "        print('Saving model')\n",
    "        manager.save()\n",
    "        print('Save completed')\n",
    "        early_stop = 0\n",
    "    else:\n",
    "        early_stop += 1\n",
    "        if early_stop == 5:\n",
    "            print('Loss has not improved for {} epochs, Early Stoppping'.format(early_stop))\n",
    "            break\n",
    "    \n",
    "    print('Epoch {} Training Loss {:.4f}, Training Acc: {:.4f}, Val Loss: {:.4f}, Val Acc: {:.4f}'.\\\n",
    "          format(epoch + 1, train_epoch_loss, train_epoch_acc, val_epoch_loss, val_epoch_acc))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (15,) and (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-d888db731f9f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Plot training vs val loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mepoch_range\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch_losses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch_range\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_epoch_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r--'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch_range\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_epoch_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'b--'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Trainin vs Val Loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tf2\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2793\u001b[0m     return gca().plot(\n\u001b[0;32m   2794\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[1;32m-> 2795\u001b[1;33m         is not None else {}), **kwargs)\n\u001b[0m\u001b[0;32m   2796\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2797\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tf2\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1664\u001b[0m         \"\"\"\n\u001b[0;32m   1665\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1666\u001b[1;33m         \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1667\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1668\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tf2\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    223\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tf2\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[1;34m(self, tup, kwargs)\u001b[0m\n\u001b[0;32m    389\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 391\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'plot'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tf2\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[1;32m--> 270\u001b[1;33m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[0;32m    271\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (15,) and (1,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training vs val loss\n",
    "epoch_range = [i for i in range(1, len(epoch_losses)+1)]\n",
    "plt.plot(epoch_range, train_epoch_losses, 'r--')\n",
    "plt.plot(epoch_range, val_epoch_losses, 'b--')\n",
    "plt.title('Trainin vs Val Loss')\n",
    "plt.legend(['Training Loss', ['Val Loss']])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epoch_range, epoch_acces, 'b--')\n",
    "plt.title('Accuracy vs Epochs')\n",
    "plt.legend(['Accuracy'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20923,
     "status": "ok",
     "timestamp": 1568675891627,
     "user": {
      "displayName": "Leo Tay",
      "photoUrl": "",
      "userId": "17143338865945125396"
     },
     "user_tz": -480
    },
    "id": "Grzkhh6lPUm1",
    "outputId": "e6d4b241-862e-4b6a-af5f-45cf787fcf30"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x195c7a96588>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restoring the latest checkpoint in checkpoint_dir\n",
    "checkpoint.restore(manager.latest_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hmZbEii3mBfI"
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((max_process_seq, max_process_seq))\n",
    "\n",
    "#     sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    inputs = [input_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_process_seq, padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([target_tokenizer.word_index['<s>']], 0)\n",
    "\n",
    "    for t in range(max_process_seq):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
    "\n",
    "        # storing the attention weights to plot later on\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += target_tokenizer.index_word[predicted_id] + ' '\n",
    "\n",
    "        if target_tokenizer.index_word[predicted_id] == '<e>':\n",
    "            return result, sentence, attention_plot\n",
    "\n",
    "        # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "      \n",
    "    return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y4LCdQKuR2uW"
   },
   "outputs": [],
   "source": [
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L_ajoU4YmBfJ"
   },
   "outputs": [],
   "source": [
    "def restore(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "\n",
    "    print('Input: {}'.format(sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "\n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1350,
     "status": "ok",
     "timestamp": 1568675928178,
     "user": {
      "displayName": "Leo Tay",
      "photoUrl": "",
      "userId": "17143338865945125396"
     },
     "user_tz": -480
    },
    "id": "W3mPyZAJB4HM",
    "outputId": "802470bf-7de8-42b5-b727-8af2dcc26c82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Data: [   2   45  277   43  188   87   44  181  117   47   38    7 3031 4872\n",
      "    1    3    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0]\n",
      "\n",
      "\n",
      "Original Data: ['<s>', 'bo', '3', 'phan', 'truoc', 'theo', 'sau', 'cuoc', 'song', 'ban', 'dau', 'cua', 'anakin', 'skywalker', '.', '<e>']\n",
      "Test Sequence: <s> bo 3 phan truoc theo sau cuoc song ban dau cua anakin skywalker . <e>\n"
     ]
    }
   ],
   "source": [
    "rand = np.random.randint(0, 16000)\n",
    "test = train_inp_data[rand]\n",
    "test = convert(input_tokenizer, test, send_back=True)\n",
    "test = ' '.join(test)\n",
    "print('Test Sequence: {}'.format(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 818
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3631,
     "status": "ok",
     "timestamp": 1568675939942,
     "user": {
      "displayName": "Leo Tay",
      "photoUrl": "",
      "userId": "17143338865945125396"
     },
     "user_tz": -480
    },
    "id": "8w3OzKgvmBfL",
    "outputId": "bd12c5d8-038c-414c-e24f-53f16ef7f310"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Data: [   2   69  222   88  131   52   30  124  209  249   41    6 4953 7095\n",
      "    1    3    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0]\n",
      "\n",
      "\n",
      "Original Data: ['<s>', 'bộ', '3', 'phần', 'trước', 'theo', 'sau', 'cuộc', 'sống', 'ban', 'đầu', 'của', 'anakin', 'skywalker', '.', '<e>']\n",
      "Original: <s> bộ 3 phần trước theo sau cuộc sống ban đầu của anakin skywalker . <e>\n",
      "Input: <s> bo 3 phan truoc theo sau cuoc song ban dau cua anakin skywalker . <e>\n",
      "Predicted translation: bộ khung . <e> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_tar = convert(target_tokenizer, train_tar_data[rand], send_back=True)\n",
    "test_tar = ' '.join(test_tar)\n",
    "print('Original: {}'.format(test_tar))\n",
    "restore(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zit9jyGOmBfN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Tensorflow.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
