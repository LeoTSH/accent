from token_list import label_tokens, strip_tokens
from string import punctuation

def process_text(in_sentence):
    table = str.maketrans('', '', punctuation)
    output = ''

    for char in in_sentence:    
        if char in strip_tokens:
            output += strip_tokens[char]
        else:
            output += char
    
    output = output.translate(table)

    return output

def generate_labels(in_sentence):
    output = []

    for char in in_sentence:
        if char in label_tokens:
            output.append(char)
        else:
            output.append('_')
    
    return ''.join(output)+'\n'

def process_dataset(dataset, dataset_type, processed_folder):
    print('Processing {} dataset'.format(dataset_type))
    inputs = []
    labels = []

    with open(dataset, 'r') as f:
        for line in f.readlines():
            inputs.append(process_text(line))
            labels.append(generate_labels(line))

    with open(processed_folder+dataset_type+'_inputs.txt', 'w') as f:
        for line in inputs:
            f.write(line)

    with open(processed_folder+dataset_type+'_labels.txt', 'w') as f:
        for line in labels:
            f.write(line)
    
    print('Completed')

def get_key(dicti, val):
  for item in dicti.items():
    if item[1] == val:
      return item[0]

def restore_text(labels, seq):
  output = ''
  for i in range(len(labels)):
    if labels[i] == '_':
      output += seq[i]
    else:
      output += labels[i]
  
  output = output.replace('pad', '')
  
  return output